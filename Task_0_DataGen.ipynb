{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28b6a2f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "28b6a2f4",
        "outputId": "42890132-6918-463a-94c5-17bd9e9156a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.14.13-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-llms-gemini\n",
            "  Downloading llama_index_llms_gemini-0.6.2-py3-none-any.whl.metadata (690 bytes)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-3.0.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (9.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.13 (from llama-index)\n",
            "  Downloading llama_index_core-0.14.13-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.6.15-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.5.6-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pillow<11,>=10.2.0 (from llama-index-llms-gemini)\n",
            "  Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.29.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.188.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (3.13.3)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (0.22.1)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading banks-2.3.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (0.28.1)\n",
            "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading llama_index_workflows-2.13.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (3.6.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (4.5.1)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (6.0.3)\n",
            "Collecting setuptools (from spacy)\n",
            "  Downloading setuptools-80.10.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.13->llama-index) (2.0.45)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (0.12.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (2.0.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (2.15.0)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.5)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf<7,>=6.1.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading pypdf-6.6.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.91-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.1)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index) (1.22.0)\n",
            "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.13->llama-index) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.13->llama-index) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.13->llama-index) (0.16.0)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-cloud-services>=0.6.91 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.91-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.13->llama-index) (3.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.90-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.90 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.90-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.89-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.89 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.89-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.88-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.88 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.88-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.87-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.87 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.87-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.86-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.86 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.86-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.85-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.85 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.85-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.84-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.84 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.84-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.83-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.82 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.83-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.82-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.82-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.81-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.81 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.81-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.80-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.80 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.80-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.79-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.79 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.79-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.78-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.78 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.78-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.2.1)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.13->llama-index)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading llama_index-0.14.13-py3-none-any.whl (7.5 kB)\n",
            "Downloading llama_index_llms_gemini-0.6.2-py3-none-any.whl (8.7 kB)\n",
            "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.14.13-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.6.15-py3-none-any.whl (26 kB)\n",
            "Downloading llama_index_readers_file-0.5.6-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
            "Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.10.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading banks-2.3.0-py3-none-any.whl (32 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_workflows-2.13.1-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.6.2-py3-none-any.whl (329 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, wrapt, setuptools, pypdf, pillow, nltk, mypy-extensions, marshmallow, colorama, typing-inspect, scikit-learn, pandas, matplotlib, griffe, deprecated, llama-index-instrumentation, llama-cloud, dataclasses-json, banks, llama-index-workflows, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-llms-gemini, llama-index-cli, llama-index-readers-llama-parse, llama-index\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.0.1\n",
            "    Uninstalling wrapt-2.0.1:\n",
            "      Successfully uninstalled wrapt-2.0.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed banks-2.3.0 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.15.0 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.13 llama-index-cli-0.5.3 llama-index-core-0.14.13 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-gemini-0.6.2 llama-index-llms-openai-0.6.15 llama-index-readers-file-0.5.6 llama-index-readers-llama-parse-0.5.1 llama-index-workflows-2.13.1 llama-parse-0.6.54 marshmallow-3.26.2 matplotlib-3.10.8 mypy-extensions-1.1.0 nltk-3.9.2 pandas-2.3.3 pillow-10.4.0 pypdf-6.6.2 scikit-learn-1.8.0 setuptools-80.10.2 striprtf-0.0.26 typing-inspect-0.9.0 wrapt-1.17.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "48e1bb0b2fde49409800957a4fdc2b57",
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -U \\\n",
        "    llama-index \\\n",
        "    llama-index-llms-gemini \\\n",
        "    google-generativeai \\\n",
        "    pandas \\\n",
        "    tenacity \\\n",
        "    nltk \\\n",
        "    spacy \\\n",
        "    scikit-learn \\\n",
        "    matplotlib \\\n",
        "    seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l7r2oDUyttYU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7r2oDUyttYU",
        "outputId": "61ad1eb7-df05-41af-c08d-7963de2404d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  loader.exec_module(module)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from llama_index.llms.gemini import Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07776f8c",
      "metadata": {
        "id": "07776f8c"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c446f220",
      "metadata": {
        "id": "c446f220"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "# genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Scwwjh60t8pE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Scwwjh60t8pE",
        "outputId": "144d4dd1-5a5c-42d0-defc-af0229bdf89f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1889364669.py:1: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/This package will no longer be supported after version 0.6.2) -- Deprecated since version 0.6.2.\n",
            "  model = Gemini(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini initialized successfully.\n"
          ]
        }
      ],
      "source": [
        "model = Gemini(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    api_key=GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "print(\"Gemini initialized successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71a9f015",
      "metadata": {
        "id": "71a9f015"
      },
      "outputs": [],
      "source": [
        "TOPICS = [\n",
        "    \"Individual vs Society\",\n",
        "    \"Moral Judgment and Interpretation of Character\",\n",
        "    \"Isolation, Withdrawal, and Inner Conflict\"\n",
        "]\n",
        "\n",
        "PARAGRAPHS_PER_TOPIC = 20   \n",
        "PARAS_PER_CALL = 4        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e02d9bf8",
      "metadata": {
        "id": "e02d9bf8"
      },
      "outputs": [],
      "source": [
        "GENERIC_BATCH_PROMPT = \"\"\"\n",
        "Write {n} independent paragraphs, each 100–200 words long, on the topic:\n",
        "\n",
        "\"{topic}\"\n",
        "\n",
        "Requirements:\n",
        "- Neutral literary prose\n",
        "- No headings or lists\n",
        "- Separate paragraphs using <PARA>\n",
        "\n",
        "Output only the paragraphs.\n",
        "\"\"\"\n",
        "\n",
        "AUSTEN_BATCH_PROMPT = \"\"\"\n",
        "Write {n} independent paragraphs, each 100–200 words long, on the topic:\n",
        "\n",
        "\"{topic}\"\n",
        "\n",
        "Write in a style inspired by Jane Austen:\n",
        "- refined sentence structure\n",
        "- subtle irony\n",
        "- social observation\n",
        "\n",
        "Constraints:\n",
        "- No references to specific works or characters\n",
        "- Separate paragraphs using <PARA>\n",
        "\n",
        "Output only the paragraphs.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z_Jx81iy0i8H",
      "metadata": {
        "id": "Z_Jx81iy0i8H"
      },
      "outputs": [],
      "source": [
        "CLASS2_FILE = \"ai_generic_checkpoint.csv\"\n",
        "CLASS3_FILE = \"ai_styled_austen_checkpoint.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K4PyNVE90js4",
      "metadata": {
        "id": "K4PyNVE90js4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def load_existing(file):\n",
        "    if os.path.exists(file):\n",
        "        return pd.read_csv(file).to_dict(\"records\")\n",
        "    return []\n",
        "\n",
        "def save_checkpoint(data, file):\n",
        "    pd.DataFrame(data).to_csv(file, index=False)\n",
        "    print(f\"[Checkpoint saved → {file}]  Total rows: {len(data)}\")\n",
        "\n",
        "def split_paragraphs(text):\n",
        "    return [p.strip() for p in text.split(\"<PARA>\") if p.strip()]\n",
        "\n",
        "def valid_length(text, min_words=100, max_words=200):\n",
        "    wc = len(text.split())\n",
        "    return min_words <= wc <= max_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rWsM5x6xy13Z",
      "metadata": {
        "id": "rWsM5x6xy13Z"
      },
      "outputs": [],
      "source": [
        "def generate_text(prompt: str) -> str:\n",
        "    response = model.complete(prompt)\n",
        "\n",
        "    if hasattr(response, \"text\") and response.text:\n",
        "        return response.text.strip()\n",
        "\n",
        "    if hasattr(response, \"raw\") and response.raw:\n",
        "        try:\n",
        "            parts = response.raw[\"candidates\"][0][\"content\"][\"parts\"]\n",
        "            texts = [p.get(\"text\", \"\") for p in parts if \"text\" in p]\n",
        "            combined = \"\\n\".join(texts).strip()\n",
        "            if combined:\n",
        "                return combined\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    raise RuntimeError(\"Gemini returned no usable text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2841f734",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2841f734",
        "outputId": "4cf7bf2f-1228-4743-d7d8-d1b0678cb3bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Class 2] Topic: Individual vs Society | Already collected: 20\n",
            "\n",
            "[Class 2] Topic: Moral Judgment and Interpretation of Character | Already collected: 8\n",
            "\n",
            "--- Generated batch for 'Moral Judgment and Interpretation of Character' ---\n",
            "\n",
            "[PARA]\n",
            " When assessing the moral fiber of a literary figure, the observer often finds themselves caught between the character’s stated intentions and the tangible consequences of their actions. This discrepancy creates a fertile ground for interpretation, as a single gesture may be viewed as either a noble  ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The allure of complex narratives often lies in the deliberate ambiguity of their protagonists, where moral clarity is sacrificed for psychological realism. When an author refuses to provide a clear ethical compass, the burden of interpretation shifts entirely to the audience, transforming the act of ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " Interpretation of character is inextricably linked to the cultural and temporal context in which a work is received, as the virtues of one era may become the vices of another. A figure celebrated for their unwavering stoicism and adherence to duty in a classical setting might be perceived as cold or ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " Ultimately, the moral judgment we pass upon a character reveals as much about the interpreter as it does about the subject of the critique. To label a character as courageous, cowardly, or deceitful is to invoke a personal standard of conduct that defines our own worldview. This reflexive quality of ...\n",
            "\n",
            "[Checkpoint saved → ai_generic_checkpoint.csv]  Total rows: 52\n",
            "\n",
            "--- Generated batch for 'Moral Judgment and Interpretation of Character' ---\n",
            "\n",
            "[PARA]\n",
            " When assessing the moral fiber of a literary figure, the observer is often caught between the clarity of an action and the opacity of its underlying motive. We tend to assign virtue or vice based on the tangible fallout of a character’s choices, yet the internal architecture of their reasoning remai ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The lens through which a character is presented dictates the boundaries of the reader’s moral empathy. An omniscient narrator might provide the psychological context necessary to forgive a character’s failings, whereas a detached or biased perspective can render the same actions inexcusable. This st ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " Literary ambiguity serves as a crucible for moral judgment, forcing the reader to navigate a landscape where traditional markers of right and wrong are intentionally obscured. Characters who inhabit this gray space challenge the comfort of binary classifications, demanding a more sophisticated level ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The interpretation of character is rarely a fixed event, but rather a process that evolves alongside the narrative’s progression. An initial impression of moral rectitude may be slowly eroded by a series of subtle compromises, just as a character introduced in a state of disgrace might find a path t ...\n",
            "\n",
            "[Checkpoint saved → ai_generic_checkpoint.csv]  Total rows: 56\n",
            "\n",
            "--- Generated batch for 'Moral Judgment and Interpretation of Character' ---\n",
            "\n",
            "[PARA]\n",
            " When assessing the moral fiber of an individual, the observer often encounters a profound disconnect between visible action and internal motivation. A character may perform a deed that appears altruistic on the surface, yet the underlying impulse might be rooted in vanity or fear. Conversely, a seem ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The environment in which a character operates serves as the essential crucible for moral evaluation. It is easy to condemn a choice when it is viewed in a vacuum, stripped of the pressures and historical burdens that shaped it. However, a more nuanced interpretation recognizes that morality is often ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " Virtue and vice are frequently two sides of the same coin, and the interpretation of character often depends on which side is currently catching the light. A trait such as unwavering loyalty can be seen as a profound moral strength in one setting, yet in another, it may manifest as a dangerous blind ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " Ultimately, the act of moral judgment reveals as much about the interpreter as it does about the character being scrutinized. Every observer brings a unique set of biases, cultural norms, and personal experiences to the task of evaluation, which inevitably colors their perception of right and wrong. ...\n",
            "\n",
            "[Checkpoint saved → ai_generic_checkpoint.csv]  Total rows: 60\n",
            "\n",
            "[Class 2] Topic: Isolation, Withdrawal, and Inner Conflict | Already collected: 20\n"
          ]
        }
      ],
      "source": [
        "class2_data = load_existing(CLASS2_FILE)\n",
        "\n",
        "for topic in TOPICS:\n",
        "    collected = sum(1 for r in class2_data if r[\"topic\"] == topic)\n",
        "    print(f\"\\n[Class 2] Topic: {topic} | Already collected: {collected}\")\n",
        "\n",
        "    while collected < PARAGRAPHS_PER_TOPIC:\n",
        "        prompt = GENERIC_BATCH_PROMPT.format(\n",
        "            topic=topic,\n",
        "            n=PARAS_PER_CALL\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            text = generate_text(prompt)\n",
        "        except Exception as e:\n",
        "            print(\"Generation failed, stopping for now:\", e)\n",
        "            break  \n",
        "\n",
        "        paras = split_paragraphs(text)\n",
        "\n",
        "        print(f\"\\n--- Generated batch for '{topic}' ---\")\n",
        "\n",
        "        for p in paras:\n",
        "            if valid_length(p):\n",
        "                print(\"\\n[PARA]\\n\", p[:300], \"...\\n\")  \n",
        "                class2_data.append({\n",
        "                    \"text\": p,\n",
        "                    \"class\": \"ai_generic\",\n",
        "                    \"topic\": topic,\n",
        "                    \"target_author\": None\n",
        "                })\n",
        "                collected += 1\n",
        "\n",
        "            if collected >= PARAGRAPHS_PER_TOPIC:\n",
        "                break\n",
        "\n",
        "        save_checkpoint(class2_data, CLASS2_FILE)\n",
        "        time.sleep(5)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1i459z6v4Ek_",
      "metadata": {
        "id": "1i459z6v4Ek_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m2POGA-dzbOX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m2POGA-dzbOX",
        "outputId": "ec53291f-dccb-46ac-d4fd-48ce5739766c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Class 3 – Austen] Topic: Individual vs Society | Already collected: 0\n",
            "\n",
            "--- Generated Austen batch for 'Individual vs Society' ---\n",
            "\n",
            "[PARA]\n",
            " The individual who dares to possess a mind of their own often finds it a most inconvenient possession. Society, in its infinite wisdom, prefers a uniform smoothness of character, much like a well-rolled gravel path where no pebble is permitted to stand higher than its neighbor. To have a particular  ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " There is no tribunal so vigilant, nor so entirely convinced of its own infallibility, as a small circle of one’s acquaintances. A person may imagine their private thoughts to be their own, yet they shall soon discover that every motive has been weighed, measured, and found wanting by the collective  ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The struggle between personal inclination and social obligation is a contest in which the latter, being better armed with the weapons of tradition and censure, almost invariably triumphs. We are taught from the cradle that our first duty is to the world, and our last to ourselves, a philosophy that  ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " Even those who pride themselves upon a sturdy independence of mind are often merely dancing to a different, though equally rigid, tune. The desire to be thought original is itself a social ambition, and the rebel is frequently as much a slave to the expectations of his circle as the most devoted fol ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 4\n",
            "\n",
            "--- Generated Austen batch for 'Individual vs Society' ---\n",
            "\n",
            "[PARA]\n",
            " The individual who possesses a mind of any particular vigor must frequently find themselves at odds with the collective expectations of their circle. It is a curious thing that while we prize a certain degree of wit in our companions, we are remarkably quick to condemn any deviation from the establi ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " There is no force more formidable than the collective observation of a small, well-ordered neighborhood. A single gentleman or lady, however modest their intentions, cannot walk across a common or choose a particular shade of ribbon without providing a week’s worth of conversation for their neighbor ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The dictates of society are never more keenly felt than when they intersect with the private inclinations of the heart. We are taught from our earliest youth that our primary duty is to maintain the dignity of our station and the expectations of our kin, yet the human spirit is notoriously prone to  ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " It is a common vanity among those of a certain temperament to believe themselves entirely independent of the whims of the world. They speak of solitude and self-sufficiency with a fervor that suggests they have quite forgotten the source of their own comforts. Yet, even the most resolute rebel finds ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 8\n",
            "\n",
            "--- Generated Austen batch for 'Individual vs Society' ---\n",
            "\n",
            "[PARA]\n",
            " The individual who dares to possess a mind of their own often finds that the collective wisdom of a neighborhood is a formidable adversary. It is a curious phenomenon that while every lady and gentleman professes a profound respect for sincerity, they are remarkably quick to condemn any deviation fr ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " There is a certain comfort to be found in the rigid structures of society, provided one does not mind the occasional stifling of a private thought. The art of conversation, as it is practiced in the most respectable circles, often requires a person to sacrifice their most interesting opinions upon t ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " To stand apart from the multitude is a luxury that few can afford and even fewer can enjoy without the accompaniment of a persistent, if polite, censure. When a person chooses to consult their own judgment rather than the prevailing whims of the season, they are immediately suspected of a most dange ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " It must be admitted that the individual, however much they may rail against the constraints of the world, is rarely content to exist entirely without its notice. There is a peculiar vanity in being misunderstood, which requires an audience to witness the misunderstanding if it is to be truly savored ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 12\n",
            "\n",
            "--- Generated Austen batch for 'Individual vs Society' ---\n",
            "\n",
            "[PARA]\n",
            " It is a truth frequently observed that a person of singular mind must often find themselves at odds with the collective wisdom of their neighbors. To possess a sentiment not shared by the general assembly is often regarded as a defect of character rather than a distinction of intellect. One must lea ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The collective eye of a small community is a formidable instrument, capable of detecting the slightest tremor in the social fabric with the precision of a jeweler examining a flawed stone. When an individual dares to prioritize their own discernment over the established prejudices of the many, they  ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " There exists a delicate balance between the dictates of one’s own conscience and the formidable requirements of one’s station. A person of true sensibility may find that their heart speaks a language entirely foreign to the dialect of the drawing-room. While society demands a certain uniformity of o ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " In the end, the individual and society must reach a sort of uneasy truce, a compromise where neither is entirely satisfied but both are sufficiently appeased. It is the way of the world that the most ardent spirits are eventually tempered by the cooling influence of general opinion, just as the most ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 16\n",
            "\n",
            "--- Generated Austen batch for 'Individual vs Society' ---\n",
            "\n",
            "[PARA]\n",
            " It is a truth universally acknowledged—though perhaps less universally enjoyed—that a person of any spirit must eventually find their edges softened by the relentless friction of polite company. To possess a mind of one’s own is a luxury that many profess to admire, yet few are willing to tolerate i ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The struggle between a private inclination and the collective wisdom of one’s circle is a drama performed daily, though often without the benefit of an audience. When a person’s heart suggests a path that the neighborhood deems imprudent, the resulting discord is felt more sharply than any physical  ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " There is no force so potent, nor so invisible, as the collective judgment of a small community. An individual may believe their character to be their own possession, yet they soon find it is merely a leasehold, subject to the whims of every idle tongue in the parish. A single deviation from the expe ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " Despite the many grievances one may harbor against the intrusions of the world, it must be admitted that a total independence is a cold and lonely prospect. The very person who rails against the absurdity of social conventions is often the first to seek the warmth of a well-lit parlor when the eveni ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 20\n",
            "\n",
            "[Class 3 – Austen] Topic: Moral Judgment and Interpretation of Character | Already collected: 0\n",
            "\n",
            "--- Generated Austen batch for 'Moral Judgment and Interpretation of Character' ---\n",
            "\n",
            "[PARA]\n",
            " It is a curious feature of human society that those with the least amount of self-knowledge are often the most eager to pronounce judgment upon the souls of their neighbors. A single afternoon’s acquaintance, conducted over the rim of a teacup or amidst the bustle of a crowded assembly, is frequentl ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The weight of one’s moral failings is often found to be in inverse proportion to the size of one’s estate. A man of considerable fortune may indulge in a thousand small cruelties and yet remain, in the eyes of the world, a most amiable and distinguished figure. His arrogance is interpreted as noble  ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " To interpret a character with any degree of accuracy requires a patience that the fashionable world seldom possesses. We prefer our acquaintances to be as legible as a well-printed volume, with their virtues and failings clearly indexed for our convenience. Yet, the human heart is rarely so obliging ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " Reputation is a fragile vessel, launched upon the uncertain waters of public opinion and subject to the whims of every passing breeze of gossip. A single whispered remark, dropped with an air of concerned confidence, can do more to dismantle a character than a lifetime of steady virtue can do to bui ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 24\n",
            "\n",
            "--- Generated Austen batch for 'Moral Judgment and Interpretation of Character' ---\n",
            "\n",
            "[PARA]\n",
            " It is a curious feature of human nature that we are never so confident in our discernment as when we possess the least evidence to support it. A single afternoon’s acquaintance, marked perhaps by a graceful bow or a well-timed compliment, is frequently deemed sufficient grounds for a total estimatio ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The possession of a substantial fortune has a most miraculous effect upon the moral clarity of one’s neighbors. A man of ten thousand a year is rarely found to be truly ill-natured; his eccentricities are termed \"originality,\" and his blatant disregard for the feelings of others is softened into \"a  ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " There exists a significant distinction between the integrity of one’s heart and the reputation one enjoys in the eyes of the world, though the two are frequently confounded by the unthinking. A lady may be celebrated for her piety and decorum while harboring a spirit of the most corrosive vanity, ju ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " To admit that one has been mistaken in the interpretation of a character is a mortification that few spirits are robust enough to endure with grace. Once we have declared a neighbor to be either a paragon of excellence or a monument of folly, we feel a certain proprietary interest in their remaining ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 28\n",
            "\n",
            "--- Generated Austen batch for 'Moral Judgment and Interpretation of Character' ---\n",
            "\n",
            "[PARA]\n",
            " It is a curious feature of human nature that we are never so confident in our discernment as when we possess the least evidence to support it. A single afternoon’s acquaintance, marked perhaps by a graceful bow or a well-timed compliment, is frequently deemed sufficient grounds for a total estimatio ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The possession of a substantial fortune has a most miraculous effect upon the moral clarity of one’s neighbors. A man of ten thousand a year is rarely found to be truly ill-natured; his obstinacy is interpreted as firmness of mind, and his arrogance is softened into a commendable dignity of station. ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " True excellence of character is a quality more often discussed in the drawing-room than practiced in the privacy of the closet. There exists a particular species of virtue that flourishes only in the presence of witnesses, where the desire for public approbation acts as a most persuasive substitute  ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " Once a judgment has been firmly established in the mind of a person who prides themselves on their sagacity, it becomes a matter of personal honor to defend it against all evidence to the contrary. To admit that one has been deceived in the character of an acquaintance is a mortification that few te ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 32\n",
            "\n",
            "--- Generated Austen batch for 'Moral Judgment and Interpretation of Character' ---\n",
            "\n",
            "[PARA]\n",
            " It is a curious feature of human nature that we are never so confident in our discernment as when we possess the least evidence to support it. A single afternoon’s acquaintance, marked perhaps by a graceful bow or a well-timed compliment, is frequently deemed sufficient grounds for a complete catalo ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The world is generally pleased to mistake a strict adherence to decorum for the possession of a sterling conscience. If a lady but manages her household with economy and receives her guests with the prescribed degree of warmth, her moral standing is considered beyond reproach. It is seldom considere ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " There is no lens so distorting to the vision as that of a large fortune. A man of ten thousand a year is rarely found to be lacking in wit, and his most tedious observations are greeted with a degree of laughter that would be denied to a poorer relation’s finest jests. We are remarkably inclined to  ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " To form a just estimate of a fellow creature is a task of such delicacy that it might well occupy a lifetime, yet we habitually dispatch it in the space of a morning visit. We seize upon a single trait—a penchant for irony or a tendency toward gravity—and construct around it a personage of our own i ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 36\n",
            "\n",
            "--- Generated Austen batch for 'Moral Judgment and Interpretation of Character' ---\n",
            "\n",
            "[PARA]\n",
            " It is a curious feature of human society that those with the least amount of self-knowledge are often the most eager to pronounce judgment upon the souls of their neighbors. A single afternoon’s observation, conducted perhaps over a lukewarm dish of tea or during a brief turn about the garden, is fr ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The world is generally inclined to grant a most liberal indulgence to the failings of the wealthy, while viewing the slight errors of the impoverished through a glass of unrelenting scrutiny. A man of significant fortune may be as ill-tempered or as indolent as he pleases, yet his neighbors will fin ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " True character is seldom found in the theater of public life, where the mask of civility is worn with such practiced ease that it becomes indistinguishable from the face beneath. A person may be celebrated in every assembly for their wit and charm, yet remain a source of constant misery to those wit ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " There is a certain stubbornness in the human mind which makes it far more agreeable to persist in an error than to admit to a mistaken impression. Once we have decided that a particular individual is either a paragon of rectitude or a vessel of folly, we become remarkably blind to any evidence that  ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 40\n",
            "\n",
            "[Class 3 – Austen] Topic: Isolation, Withdrawal, and Inner Conflict | Already collected: 0\n",
            "\n",
            "--- Generated Austen batch for 'Isolation, Withdrawal, and Inner Conflict' ---\n",
            "\n",
            "[PARA]\n",
            " The world is seldom satisfied with a person who prefers the company of their own thoughts to the clamour of a crowded drawing-room. To withdraw from the gaze of one’s neighbours is frequently interpreted as a mark of either profound melancholy or insufferable pride, for society cannot conceive of a  ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " There is a peculiar misery in possessing a mind that is perpetually at war with its own inclinations. A lady may sit quite still, her needlework progressing with admirable regularity, while within her breast a tempest of indecision rages with a violence that would astonish her companions. This inner ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " It is often remarked that solitude is the nurse of wisdom, yet it is more frequently the refuge of those who find the world’s demands upon their temper to be quite beyond their current means. To withdraw from the social circle is a privilege often mistaken for a penance. When the mind is occupied by ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " To be at odds with oneself is a condition that no amount of external prosperity can alleviate. A person may be blessed with every advantage of fortune and connection, yet remain a prisoner to a divided will. This internal discord necessitates a degree of withdrawal that the world is quick to censure ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 44\n",
            "\n",
            "--- Generated Austen batch for 'Isolation, Withdrawal, and Inner Conflict' ---\n",
            "\n",
            "[PARA]\n",
            " There is a peculiar species of misery reserved for those who, while surrounded by the most agreeable company, find their spirits perversely inclined toward the garden gate. To withdraw from a drawing-room is often interpreted as a slight against the hostess, yet the heart frequently demands a sanctu ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The human mind is a theater of constant and often invisible warfare, where the forces of inclination and judgment are perpetually at odds. When a person of any sensibility finds their desires in direct opposition to their better sense, the result is a most distressing state of inner conflict. Such a ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " It is often remarked that nothing is so conducive to a settled mind as the steady routine of a country life, yet even the most tranquil surroundings cannot prevent the intrusion of a restless spirit. To feel isolated in the midst of a crowded assembly is a trial of the highest order, requiring a deg ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " A disposition toward melancholy is seldom viewed with favor by those who consider a cheerful temper to be the primary virtue of a companion. When an individual chooses to sequester themselves from the usual rounds of visits and balls, the neighborhood is quick to assign a motive, usually one involvi ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 48\n",
            "\n",
            "--- Generated Austen batch for 'Isolation, Withdrawal, and Inner Conflict' ---\n",
            "\n",
            "[PARA]\n",
            " There is a peculiar species of misery reserved for those who, while surrounded by the most agreeable company, find their spirits perversely inclined toward the garden gate. To withdraw from a drawing-room is often interpreted as a slight against the hostess, yet the heart frequently demands a seclus ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " A person of any sensibility must occasionally find that their greatest enemy resides within the very breast they are taught to govern with such composure. To be at variance with oneself is a condition far more exhausting than any public disagreement, for there is no mediator to be found in the priva ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " It is often remarked that solitude is the nurse of wisdom, yet in a society where every hour is mapped by visits and every thought is expected to be shared, the pursuit of it is viewed as a most suspicious eccentricity. To withdraw from the common gaze is to invite the most imaginative censures of o ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " There is no greater trial for a person of refined feeling than the necessity of maintaining a cheerful aspect when the heart is in a state of absolute rebellion. To withdraw to one’s dressing-room under the pretext of a fatigue that is more mental than physical is a stratagem as old as civilization  ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 52\n",
            "\n",
            "--- Generated Austen batch for 'Isolation, Withdrawal, and Inner Conflict' ---\n",
            "\n",
            "[PARA]\n",
            " There is a peculiar species of misery reserved for those who, while surrounded by the most agreeable company, find their spirits perversely inclined toward the garden gate. To withdraw from a drawing-room is often interpreted as a slight against the hostess, yet the heart frequently demands a seclus ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " The decision to retreat from the world is seldom the result of a sudden whim, but rather the slow accumulation of those small, stinging disappointments that characterize a social existence. When the mind is at variance with itself, the most splendid assembly offers no consolation; indeed, the bright ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " It is often remarked that a quiet disposition is the hallmark of a contented mind, yet how frequently does a tranquil exterior mask a spirit in the throes of a most unquiet revolution. To withdraw from the bustle of the neighborhood is to invite the censure of every lady with a spare afternoon and a ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " There is a certain dignity in withdrawal which the world, in its haste to be entertained, rarely pauses to admire. When a heart is divided against itself, the most elegant parlor becomes a cage, and the most polite conversation a series of obstacles to be surmounted with wearying fortitude. To seek  ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 56\n",
            "\n",
            "--- Generated Austen batch for 'Isolation, Withdrawal, and Inner Conflict' ---\n",
            "\n",
            "[PARA]\n",
            " There is a peculiar species of misery reserved for those who, while surrounded by the most agreeable company, find their spirits perversely inclined toward the garden gate. To withdraw from a drawing-room is often interpreted as a slight against the hostess, yet the inner tumult of a mind at odds wi ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " A young person of sensitive disposition often discovers that the world is a place of much noise and very little consequence. In such instances, the sanctuary of one’s own chamber becomes not merely a preference, but a necessity for the preservation of one’s temper. There is a certain dignity in with ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " Society is seldom inclined to forgive a person who prefers their own thoughts to the collective wisdom of a dinner party. To seek isolation is frequently branded as an affectation of superior intellect or, worse, a symptom of a sullen heart. Yet, the inner conflict of one who must choose between the ...\n",
            "\n",
            "\n",
            "[PARA]\n",
            " There is a dangerous allure in the notion that one may be entirely self-sufficient, independent of the whims and judgments of others. A person may retreat into a fortress of their own making, convinced that by avoiding the attachments of the world, they are also avoiding its disappointments. This wi ...\n",
            "\n",
            "[Checkpoint saved → ai_styled_austen_checkpoint.csv]  Total rows: 60\n"
          ]
        }
      ],
      "source": [
        "class3_data = load_existing(CLASS3_FILE)\n",
        "\n",
        "for topic in TOPICS:\n",
        "    collected = sum(1 for r in class3_data if r[\"topic\"] == topic)\n",
        "    print(f\"\\n[Class 3 – Austen] Topic: {topic} | Already collected: {collected}\")\n",
        "\n",
        "    while collected < PARAGRAPHS_PER_TOPIC:\n",
        "        prompt = AUSTEN_BATCH_PROMPT.format(\n",
        "            topic=topic,\n",
        "            n=PARAS_PER_CALL\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            text = generate_text(prompt)\n",
        "        except Exception as e:\n",
        "            print(\"Generation failed, stopping for now:\", e)\n",
        "            break\n",
        "\n",
        "        paras = split_paragraphs(text)\n",
        "\n",
        "        print(f\"\\n--- Generated Austen batch for '{topic}' ---\")\n",
        "\n",
        "        for p in paras:\n",
        "            if valid_length(p):\n",
        "                print(\"\\n[PARA]\\n\", p[:300], \"...\\n\")\n",
        "                class3_data.append({\n",
        "                    \"text\": p,\n",
        "                    \"class\": \"ai_styled\",\n",
        "                    \"topic\": topic,\n",
        "                    \"target_author\": \"Jane Austen\"\n",
        "                })\n",
        "                collected += 1\n",
        "\n",
        "            if collected >= PARAGRAPHS_PER_TOPIC:\n",
        "                break\n",
        "\n",
        "        save_checkpoint(class3_data, CLASS3_FILE)\n",
        "        time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbPEACz54GGX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbPEACz54GGX",
        "outputId": "7bd7ecca-6a01-4a07-c1e3-be361ea4952c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial size: 60\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "df = pd.read_csv(\"ai_styled_austen_checkpoint.csv\")\n",
        "\n",
        "print(\"Initial size:\", len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uZtoacex4JXF",
      "metadata": {
        "id": "uZtoacex4JXF"
      },
      "outputs": [],
      "source": [
        "def clean_text_light(text):\n",
        "    # remove stray delimiters if any\n",
        "    text = text.replace(\"<PARA>\", \" \")\n",
        "\n",
        "    # normalize whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "df[\"text\"] = df[\"text\"].apply(clean_text_light)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RYWN5TLi4LHq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYWN5TLi4LHq",
        "outputId": "085a7b73-1d2b-491d-b96b-9fc05efe1899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After length filtering: 60\n"
          ]
        }
      ],
      "source": [
        "def word_count(text):\n",
        "    return len(text.split())\n",
        "\n",
        "df[\"word_count\"] = df[\"text\"].apply(word_count)\n",
        "\n",
        "df = df[(df[\"word_count\"] >= 100) & (df[\"word_count\"] <= 200)]\n",
        "\n",
        "print(\"After length filtering:\", len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s6jnms_u4M8z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6jnms_u4M8z",
        "outputId": "50f1f69b-718e-4352-f455-0e66553adb22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "topic\n",
            "Individual vs Society                             20\n",
            "Isolation, Withdrawal, and Inner Conflict         20\n",
            "Moral Judgment and Interpretation of Character    20\n",
            "dtype: int64\n",
            "count     60.000000\n",
            "mean     169.866667\n",
            "std        9.204764\n",
            "min      147.000000\n",
            "25%      163.000000\n",
            "50%      170.500000\n",
            "75%      176.000000\n",
            "max      188.000000\n",
            "Name: word_count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(df.groupby(\"topic\").size())\n",
        "print(df[\"word_count\"].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "knqtaffn4QBh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knqtaffn4QBh",
        "outputId": "86fa3c18-1577-4b00-cbb2-08e3d23afd1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved ai_generic_final.csv\n"
          ]
        }
      ],
      "source": [
        "df = df.drop(columns=[\"word_count\"])\n",
        "\n",
        "df.to_csv(\"ai_generic_final.csv\", index=False)\n",
        "\n",
        "print(\"Saved ai_generic_final.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-Vc6LqYl4Tne",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-Vc6LqYl4Tne",
        "outputId": "273e8b4a-d421-4a88-eecf-41d0e1d0d12e"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_5f342117-b43b-4f99-81e4-a9465e69e436\", \"ai_generic_final.csv\", 64388)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"ai_generic_final.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
